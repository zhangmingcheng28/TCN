{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3294a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Time    : 5/5/2022 9:23 AM\n",
    "@Author  : Mingcheng\n",
    "@FileName: \n",
    "@Description: \n",
    "@Package dependency:\n",
    "\"\"\"\n",
    "\"\"\" A very simple Temporal Convolutional Networks baseline\n",
    "* TCN implementation is adapted from https://github.com/locuslab/TCN\n",
    "* This is a very small dataset, so it's very easy to overfit. Tune carefully.\n",
    "* Check the \"Output\" tab for training logs.\n",
    "\"\"\"\n",
    "from subprocess import call\n",
    "import os\n",
    "\n",
    "FNULL = open(os.devnull, 'w')\n",
    "call(\"pip install https://github.com/ceshine/pytorch_helper_bot/archive/0.0.3.zip\".split(\" \"), stdout=FNULL,\n",
    "     stderr=FNULL)\n",
    "\n",
    "# set SEED\n",
    "os.environ[\"SEED\"] = \"42\"\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# ======================\n",
    "#     TCN Components\n",
    "# ======================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv2d(n_inputs, n_outputs, (1, kernel_size),\n",
    "                                           stride=stride, padding=0, dilation=dilation))\n",
    "        self.pad = torch.nn.ZeroPad2d((padding, 0, 0, 0))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.conv2 = weight_norm(nn.Conv2d(n_outputs, n_outputs, (1, kernel_size),\n",
    "                                           stride=stride, padding=0, dilation=dilation))\n",
    "        self.net = nn.Sequential(self.pad, self.conv1, self.relu, self.dropout,\n",
    "                                 self.pad, self.conv2, self.relu, self.dropout)\n",
    "        self.downsample = nn.Conv1d(\n",
    "            n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x.unsqueeze(2)).squeeze(2)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i - 1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size - 1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "# ======================\n",
    "#     Dataset Utils\n",
    "# ======================\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "def get_dataset(x, y):\n",
    "    return TensorDataset(\n",
    "        torch.from_numpy(x).float(),\n",
    "        torch.from_numpy(y).float()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_dataloader(x: np.array, y: np.array, batch_size: int, shuffle: bool = True, num_workers: int = 0):\n",
    "    dataset = get_dataset(x, y)\n",
    "    return DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ndarray(embedding_values):\n",
    "    results = []\n",
    "    for row in embedding_values:\n",
    "        arr = np.array(row)\n",
    "        results.append(\n",
    "            np.pad(arr, ((10 - arr.shape[0], 0), (0, 0)), 'constant')\n",
    "        )\n",
    "    # shape: (examples, emb_dim, seq_length)\n",
    "    return np.transpose(np.stack(results), (0, 2, 1))\n",
    "\n",
    "\n",
    "def read_dataset(data_dir=Path(\"data/\")):\n",
    "    if isinstance(data_dir, str):\n",
    "        data_dir = Path(data_dir)\n",
    "    df_train = pd.read_json(data_dir / 'train.json')\n",
    "    df_test = pd.read_json(data_dir / 'test.json')\n",
    "    x_train = get_ndarray(df_train.audio_embedding)\n",
    "    y_train = df_train.is_turkey.values\n",
    "    x_test = get_ndarray(df_test.audio_embedding)\n",
    "    test_id = df_test.vid_id\n",
    "    return x_train, y_train, x_test, test_id\n",
    "\n",
    "\n",
    "# ===============================================\n",
    "#     Model Creation, Training, and Inference\n",
    "# ==============================================\n",
    "import logging\n",
    "from pytorch_helper_bot.bot import BaseBot\n",
    "from pytorch_helper_bot.lr_scheduler import TriangularLR\n",
    "from pytorch_helper_bot.weight_decay import WeightDecayOptimizerWrapper\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TurkeyBot(BaseBot):\n",
    "    name = \"Turkey\"\n",
    "\n",
    "    def __init__(self, model, train_loader, val_loader, *, optimizer,\n",
    "                 avg_window=20, log_dir=\"./cache/logs/\",\n",
    "                 log_level=logging.INFO, checkpoint_dir=\"./cache/model_cache/\"):\n",
    "        super().__init__(\n",
    "            model, train_loader, val_loader,\n",
    "            optimizer=optimizer, avg_window=avg_window,\n",
    "            log_dir=log_dir, log_level=log_level, checkpoint_dir=checkpoint_dir,\n",
    "            batch_idx=0, echo=False, device=DEVICE\n",
    "        )\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.loss_format = \"%.8f\"\n",
    "\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TCNModel, self).__init__()\n",
    "        self.tcn = TemporalConvNet(\n",
    "            128, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.decoder = nn.Linear(num_channels[-1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.dropout(self.tcn(x)[:, :, -1]))\n",
    "\n",
    "\n",
    "def main():\n",
    "    x_train, y_train, x_test, test_id = read_dataset(\"F:\\githubClone\\TCN\\dont-call-me-turkey\")\n",
    "\n",
    "    test_loader = get_dataloader(\n",
    "        x_test, np.zeros(x_test.shape[0]), batch_size=128, shuffle=False)\n",
    "\n",
    "    test_pred_list, val_losses = [], []\n",
    "    kf = StratifiedKFold(n_splits=8, random_state=31829, shuffle=True)\n",
    "    for train_index, valid_index in kf.split(x_train, y_train):\n",
    "        train_loader = get_dataloader(\n",
    "            x_train[train_index], y_train[train_index],\n",
    "            batch_size=32, shuffle=True\n",
    "        )\n",
    "        val_loader = get_dataloader(\n",
    "            x_train[valid_index], y_train[valid_index],\n",
    "            batch_size=128, shuffle=False\n",
    "        )\n",
    "\n",
    "        model = TCNModel(num_channels=[20] * 2, kernel_size=3, dropout=0.25)\n",
    "        model.to(DEVICE)\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), betas=(0.9, 0.999), lr=1e-3, weight_decay=0)\n",
    "        # optimizer = WeightDecayOptimizerWrapper(\n",
    "        #     optimizer, weight_decay=5e-3\n",
    "        # )\n",
    "        batches_per_epoch = len(train_loader)\n",
    "        bot = TurkeyBot(\n",
    "            model, train_loader, val_loader,\n",
    "            optimizer=optimizer, avg_window=batches_per_epoch\n",
    "        )\n",
    "        n_steps = batches_per_epoch * 20\n",
    "        scheduler = TriangularLR(\n",
    "            optimizer, max_mul=8, ratio=9,\n",
    "            steps_per_cycle=n_steps\n",
    "        )\n",
    "        bot.train(\n",
    "            n_steps,\n",
    "            log_interval=batches_per_epoch // 2,\n",
    "            snapshot_interval=batches_per_epoch,\n",
    "            early_stopping_cnt=10, scheduler=scheduler)\n",
    "        val_preds = torch.sigmoid(bot.predict_avg(\n",
    "            val_loader, k=3, is_test=True).cpu()).numpy().clip(1e-5, 1 - 1e-5)\n",
    "        loss = log_loss(y_train[valid_index], val_preds)\n",
    "        if loss > 0.2:\n",
    "            # Ditch folds that perform terribly\n",
    "            bot.remove_checkpoints(keep=0)\n",
    "            continue\n",
    "        print(\"AUC: %.6f\" % roc_auc_score(y_train[valid_index], val_preds))\n",
    "        print(\"Val loss: %.6f\" % loss)\n",
    "        val_losses.append(loss)\n",
    "        test_pred_list.append(torch.sigmoid(bot.predict_avg(\n",
    "            test_loader, k=3, is_test=True).cpu()).numpy().clip(1e-5, 1 - 1e-5))\n",
    "        bot.remove_checkpoints(keep=0)\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    test_preds = np.mean(test_pred_list, axis=0)\n",
    "    print(\"Validation losses: %.6f +- %.6f\" %\n",
    "          (np.mean(val_losses), np.std(val_losses)))\n",
    "\n",
    "    df_sub = pd.DataFrame({\n",
    "        \"vid_id\": test_id,\n",
    "        \"is_turkey\": test_preds\n",
    "    })\n",
    "    df_sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "\n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15993d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
